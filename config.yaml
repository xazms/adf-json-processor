# ========================================
# üîπ ADF JSON Processor - Configuration
# ========================================

# ‚úÖ General settings
project:
  name: "ADF JSON Processor"
  version: "0.1.4"
  description: "Processes ADF JSON files and stores them as Delta tables."
  author: "Azmir Salihovic"
  email: "${PROJECT_AUTHOR_EMAIL}"  # üëà Load from environment

# ‚úÖ Logging settings
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
  format: "[%(levelname)s] - %(message)s"
  log_to_file: false  # If true, logs are written to `logs/adf_processor.log`

# ‚úÖ Authentication settings (‚ö†Ô∏è Store secrets in environment variables)
authentication:
  method: "${AUTH_METHOD}"  # Options: PAT (Personal Access Token), OAuth2
  token_secret_name: "${AZURE_KEYVAULT_SECRET}"  # üëà Load from Key Vault
  keyvault_scope: "${AZURE_KEYVAULT_SCOPE}"

# ‚úÖ Azure DevOps Repository settings
azure_devops:
  organization: "${AZURE_DEVOPS_ORG}"
  project: "${AZURE_DEVOPS_PROJECT}"
  repository: "${AZURE_DEVOPS_REPO}"
  branch: "${AZURE_DEVOPS_BRANCH}"
  folder_path: "${AZURE_DEVOPS_FOLDER_PATH}"

# ‚úÖ Storage settings
storage:
  source_account: "${SOURCE_STORAGE_ACCOUNT}"
  destination_account: "${DESTINATION_STORAGE_ACCOUNT}"
  dataset_identifier: "${DATASET_IDENTIFIER}"
  source_filename: "*"

# ‚úÖ Processing settings
processing:
  include_types: ["DatabricksNotebook", "ExecutePipeline", "ExecuteDataFlow"]
  debug_mode: "${DEBUG_MODE}"  # üëà Load from environment
  remove_duplicates: "${REMOVE_DUPLICATES}"  # Automatically removes duplicates in merge

# ‚úÖ Table Management settings
table_management:
  create_if_not_exists: true
  merge_strategy: "upsert"  # Options: upsert, append, replace
  default_partition_column: "CreatedDate"

# ‚úÖ Testing & Validation settings
testing:
  enable_tests: "${ENABLE_TESTS}"
  test_file: "sample_adf_pipeline.json"

# ‚úÖ GitHub Actions CI settings
ci:
  enabled: true
  lint_checks: ["flake8", "black"]
  test_runner: "pytest"