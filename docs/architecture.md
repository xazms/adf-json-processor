# üèó Architecture Overview

## 1Ô∏è‚É£ Introduction

The **ADF JSON Processor** is a Python-based framework designed to process **Azure Data Factory (ADF) JSON files**. It converts them into structured **PySpark DataFrames** and stores them as **Delta tables** in **Azure Data Lake Storage**.

### üîπ Key Features:
- **Standardizes ADF JSON files** for easier processing.
- **Modular structure** for flexibility and maintainability.
- **Supports Delta Lake storage** for efficient data querying.
- **Handles dependencies** between ADF activities and pipelines.

---

## 2Ô∏è‚É£ System Architecture

The system consists of **six core components**, each handling a specific aspect of the processing workflow.

### üîπ **Core Components**
| Component         | Description                                      |
|------------------|--------------------------------------------------|
| **1Ô∏è‚É£ Authentication**  | Authenticates with Azure DevOps via PAT.  |
| **2Ô∏è‚É£ Configuration**   | Manages settings and environment variables. |
| **3Ô∏è‚É£ File Handling**   | Retrieves and reads ADF JSON files. |
| **4Ô∏è‚É£ Processing**      | Parses JSON, extracts pipelines, activities, and dependencies. |
| **5Ô∏è‚É£ Storage**         | Creates or merges Delta tables in ADLS. |
| **6Ô∏è‚É£ Utilities**       | Provides logging, debugging, and helper functions. |

---

## 3Ô∏è‚É£ Workflow Process

The system follows a **6-step process** to handle ADF JSON data efficiently.

### üîπ **Processing Steps**
1. **Fetch JSON files** from Azure DevOps.
2. **Parse JSON** and extract relevant pipeline data.
3. **Convert JSON to PySpark DataFrames**.
4. **Validate and clean data**.
5. **Create or Merge Delta tables** in Azure Data Lake.
6. **Log results and errors** for monitoring.

---

## 4Ô∏è‚É£ Components in Detail

### üîπ **1. Authentication (`auth/`)**
- Supports **Personal Access Token (PAT)** authentication for **Azure DevOps**.
- Can be extended for **OAuth2 authentication**.

### üîπ **2. Configuration (`config/`)**
- Loads settings from `config.yaml`.
- Manages **Databricks workspace details** and **storage credentials**.

### üîπ **3. File Handling (`file_handling/`)**
- Retrieves ADF JSON files using **Azure DevOps API**.
- Filters and organizes ADF files for processing.

### üîπ **4. Processing Module (`processing/`)**
- **Parses JSON files** into structured DataFrames.
- Extracts **pipelines, activities, dependencies**.
- Supports **incremental processing** for efficiency.

### üîπ **5. Storage Management (`storage/`)**
- Creates **Delta tables** if they do not exist.
- Supports **MERGE operations** for **incremental updates**.
- Ensures **data consistency** by handling duplicates.

### üîπ **6. Utilities (`utils/`)**
- **Logging**: Debugging, error handling, and execution logs.
- **Helper functions**: JSON parsing, hash generation, and formatting.
- **SQL query generation** for Delta table operations.

---

## 5Ô∏è‚É£ Data Flow Diagram

```plaintext
Step 1Ô∏è‚É£: Fetch JSON Files (Azure DevOps)
    ‚¨á
Step 2Ô∏è‚É£: Parse JSON into Structured Format
    ‚¨á
Step 3Ô∏è‚É£: Convert to PySpark DataFrames
    ‚¨á
Step 4Ô∏è‚É£: Validate & Clean Data
    ‚¨á
Step 5Ô∏è‚É£: Create or Merge Delta Tables (Azure Data Lake)
    ‚¨á
Step 6Ô∏è‚É£: Log Results & Monitor Errors